{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_PyTorch_4_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/UVXLR1CaYeWJThaxKfrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiyazovIlia/PyTorch-1/blob/lesson-4/HW_PyTorch_4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JEYa1J-DGSk0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
        "\n",
        "\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI7owM4EGS5V",
        "outputId": "7199b7a1-9b3e-4ef1-c686-a6c672a469a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans_actions = transforms.Compose([transforms.Resize(40),\n",
        "                                    transforms.RandomCrop(32, padding=3), \n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
        "    return X_train, X_test\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)"
      ],
      "metadata": {
        "id": "b6iHZhG9GUFE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
      ],
      "metadata": {
        "id": "YSXjcnEqJQkG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=250,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=250,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "UsC7jinrGVUs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly',\n",
        "           'camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup',\n",
        "           'dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','keyboard','lamp','lawn_mower',\n",
        "           'leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange',\n",
        "           'orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit',\n",
        "           'raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel',\n",
        "           'streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip',\n",
        "           'turtle','wardrobe','whale','willow_tree','wolf','woman','worm']\n",
        "len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJyLaMQcGVME",
        "outputId": "f975f98e-f8c5-44a0-a3d6-45f584706002"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YZHSO8O8Gfm9",
        "outputId": "8040dbbf-6f6b-40b4-cefc-e97d90ce7a3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dp_one = nn.Dropout(0.2)\n",
        "        self.dp_two = nn.Dropout(0.2)\n",
        "        \n",
        "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
        "        self.conv_one = torch.nn.Conv2d(3, 30, kernel_size=3,padding=1)\n",
        "        self.bn_two = torch.nn.BatchNorm2d(30) \n",
        "        self.conv_two = torch.nn.Conv2d(30, 90, kernel_size=3,padding=1)\n",
        "        self.bn_three = torch.nn.BatchNorm2d(90)\n",
        "        self.conv_three = torch.nn.Conv2d(90, 120, kernel_size=3,padding=1)\n",
        "\n",
        "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
        "        self.conv_four = torch.nn.Conv2d(120, 160, kernel_size=3, padding=1)\n",
        "\n",
        "        self.bn_five = torch.nn.BatchNorm2d(160)\n",
        "        self.fc1 = torch.nn.Linear(640, 200)\n",
        "        self.fc2 = torch.nn.Sigmoid()\n",
        "        self.out = torch.nn.Linear(200, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn_one(x)\n",
        "        x = self.conv_one(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_two(x)\n",
        "        x = self.conv_two(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_three(x)\n",
        "        x = self.conv_three(x)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.bn_four(x)\n",
        "        x = self.conv_four(x)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_five(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp_one(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dp_two(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.out(x)\n",
        "       \n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ripPTVJcGXUU",
        "outputId": "87789377-88ba-4976-9f3c-fa0dbbe25463"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp_one): Dropout(p=0.2, inplace=False)\n",
            "  (dp_two): Dropout(p=0.2, inplace=False)\n",
            "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_two): Conv2d(30, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_three): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_three): Conv2d(90, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_four): Conv2d(120, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_five): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=640, out_features=200, bias=True)\n",
            "  (fc2): Sigmoid()\n",
            "  (out): Linear(in_features=200, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "S6bVjt2cGZTu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "net.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 50 == 0:    # печатаем каждые 50 mini-batches\n",
        "            net.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = net(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGw-HvQrGZQ8",
        "outputId": "275eddd3-09f9-42b4-d2e5-1c32491d06e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/190]. Loss: 0.019. Acc: 0.004. Test acc: 0.011\n",
            "Epoch [1/10]. Step [51/190]. Loss: 0.018. Acc: 0.028. Test acc: 0.049\n",
            "Epoch [1/10]. Step [101/190]. Loss: 0.017. Acc: 0.053. Test acc: 0.064\n",
            "Epoch [1/10]. Step [151/190]. Loss: 0.016. Acc: 0.065. Test acc: 0.080\n",
            "Epoch [2/10]. Step [1/190]. Loss: 0.016. Acc: 0.080. Test acc: 0.071\n",
            "Epoch [2/10]. Step [51/190]. Loss: 0.016. Acc: 0.082. Test acc: 0.080\n",
            "Epoch [2/10]. Step [101/190]. Loss: 0.016. Acc: 0.089. Test acc: 0.109\n",
            "Epoch [2/10]. Step [151/190]. Loss: 0.015. Acc: 0.100. Test acc: 0.106\n",
            "Epoch [3/10]. Step [1/190]. Loss: 0.015. Acc: 0.116. Test acc: 0.112\n",
            "Epoch [3/10]. Step [51/190]. Loss: 0.015. Acc: 0.119. Test acc: 0.100\n",
            "Epoch [3/10]. Step [101/190]. Loss: 0.015. Acc: 0.118. Test acc: 0.106\n",
            "Epoch [3/10]. Step [151/190]. Loss: 0.015. Acc: 0.124. Test acc: 0.132\n",
            "Epoch [4/10]. Step [1/190]. Loss: 0.014. Acc: 0.160. Test acc: 0.142\n",
            "Epoch [4/10]. Step [51/190]. Loss: 0.014. Acc: 0.143. Test acc: 0.156\n",
            "Epoch [4/10]. Step [101/190]. Loss: 0.014. Acc: 0.149. Test acc: 0.158\n",
            "Epoch [4/10]. Step [151/190]. Loss: 0.014. Acc: 0.152. Test acc: 0.149\n",
            "Epoch [5/10]. Step [1/190]. Loss: 0.014. Acc: 0.172. Test acc: 0.140\n",
            "Epoch [5/10]. Step [51/190]. Loss: 0.014. Acc: 0.171. Test acc: 0.140\n",
            "Epoch [5/10]. Step [101/190]. Loss: 0.014. Acc: 0.168. Test acc: 0.159\n",
            "Epoch [5/10]. Step [151/190]. Loss: 0.014. Acc: 0.173. Test acc: 0.173\n",
            "Epoch [6/10]. Step [1/190]. Loss: 0.013. Acc: 0.208. Test acc: 0.159\n",
            "Epoch [6/10]. Step [51/190]. Loss: 0.013. Acc: 0.184. Test acc: 0.191\n",
            "Epoch [6/10]. Step [101/190]. Loss: 0.013. Acc: 0.191. Test acc: 0.199\n",
            "Epoch [6/10]. Step [151/190]. Loss: 0.013. Acc: 0.201. Test acc: 0.187\n",
            "Epoch [7/10]. Step [1/190]. Loss: 0.013. Acc: 0.172. Test acc: 0.195\n",
            "Epoch [7/10]. Step [51/190]. Loss: 0.013. Acc: 0.204. Test acc: 0.200\n",
            "Epoch [7/10]. Step [101/190]. Loss: 0.013. Acc: 0.205. Test acc: 0.216\n",
            "Epoch [7/10]. Step [151/190]. Loss: 0.013. Acc: 0.210. Test acc: 0.208\n",
            "Epoch [8/10]. Step [1/190]. Loss: 0.012. Acc: 0.260. Test acc: 0.202\n",
            "Epoch [8/10]. Step [51/190]. Loss: 0.013. Acc: 0.221. Test acc: 0.232\n",
            "Epoch [8/10]. Step [101/190]. Loss: 0.013. Acc: 0.228. Test acc: 0.228\n",
            "Epoch [8/10]. Step [151/190]. Loss: 0.013. Acc: 0.219. Test acc: 0.209\n",
            "Epoch [9/10]. Step [1/190]. Loss: 0.012. Acc: 0.216. Test acc: 0.213\n",
            "Epoch [9/10]. Step [51/190]. Loss: 0.013. Acc: 0.223. Test acc: 0.214\n",
            "Epoch [9/10]. Step [101/190]. Loss: 0.013. Acc: 0.228. Test acc: 0.215\n",
            "Epoch [9/10]. Step [151/190]. Loss: 0.012. Acc: 0.226. Test acc: 0.208\n",
            "Epoch [10/10]. Step [1/190]. Loss: 0.013. Acc: 0.228. Test acc: 0.202\n",
            "Epoch [10/10]. Step [51/190]. Loss: 0.012. Acc: 0.230. Test acc: 0.237\n",
            "Epoch [10/10]. Step [101/190]. Loss: 0.012. Acc: 0.237. Test acc: 0.220\n",
            "Epoch [10/10]. Step [151/190]. Loss: 0.012. Acc: 0.241. Test acc: 0.229\n",
            "Training is finished!\n"
          ]
        }
      ]
    }
  ]
}